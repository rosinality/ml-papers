ì´ë²ˆ ì£¼ì˜ ë…¼ë¬¸
ì—°ë§ì´ê¸°ë„ í•˜ê³  í•´ì„œ ë…¼ë¬¸ ëª©ë¡ì„ ë³´ë‹¤ê°€ ì˜¬í•´ ë”¥ ëŸ¬ë‹ ì—…ê³„ì˜ í° í˜ì‹ ì—ëŠ” ë¬´ì—‡ì´ ìˆì—ˆë‚˜ í•˜ëŠ” ìƒê°ì„ í•´ë´¤ë‹¤. ë‚˜ë¼ë©´ ëŒ€ëµ ì•„ë˜ ê°™ì€ ì£¼ì œë“¤ì„ ê¼½ì„ ê²ƒ ê°™ë‹¤. ëŒ€ì¶© ë½‘ì€ ê²ƒì´ê¸´ í•˜ì§€ë§Œ.
implicit neural representation
generative model (denoising diffusion, score based model, vae)
augmentation for gan
detr
self supervision & semi supervision
efficient attention
robustness
lm & bertology
ì´ëŸ° ì£¼ì œë“¤ì„ ê°€ì§€ê³  ì—°ë§ ê¸°ë… ì´ë²¤íŠ¸(?) ë¹„ìŠ·í•œ ê²ƒì„ í•´ë³´ë©´ ì–´ë–¨ê¹Œ í•˜ëŠ” ìƒê°ì„ í•˜ê³  ìˆë‹¤. ìœ„ì˜ ì£¼ì œë“¤ì— ëŒ€í•´ì„œ ê°œê´„ì ìœ¼ë¡œ ë‹¤ë¤„ë³¸ë‹¤ë“ ì§€, ì•„ë‹ˆë©´ ìœ„ ì£¼ì œë“¤ì— ëŒ€í•œ ì£¼ìš” ë…¼ë¬¸ ëª©ë¡ì„ ì •ë¦¬í•œë‹¤ë“ ì§€, ëª‡ ë…¼ë¬¸ì„ ë½‘ì•„ì„œ ë¦¬ë·°ë¥¼ í•œë‹¤ë“ ì§€, í•„ìˆ˜...ëŠ” ë¬´ìŠ¨ ê¶Œìœ„ê°€ ìˆì§€ë„ ì•Šì€ ì…ì¥ì—ì„œ ë„ˆë¬´ ê°•ì œì ì¸ ê²ƒ ê°™ìœ¼ë‹ˆ ê¶Œì¥ ë¦¬ë”© ë¦¬ìŠ¤íŠ¸ ê°™ì€ ê±¸ ë§Œë“ ë‹¤ë“ ì§€ ë“±ë“±. ê·¸ëŸ°ë° ìƒê°í•´ë³´ë©´ ì–´ì°¨í”¼ ë‹¤ë“¤ ì½ì–´ë³¸ ë…¼ë¬¸ì¼ í…ë° ê·¸ëŸ° ê²Œ í•„ìš”í•œê°€ ì‹¶ê¸°ë„ í•˜ë‹¤. ê·¸ëƒ¥ ì´ëŸ° ì£¼ì œë“¤ì— ëŒ€í•œ ì“¸ë° ì—†ëŠ” ì†Œë¦¬ë‚˜ ì¢€ í•˜ëŠ” ê²Œ ë‚˜ì„ì§€ë„.
ì–´ì¨Œë“ ! ì´ë²ˆ ì£¼ì˜ ë…¼ë¬¸ì—ëŠ” ìœ„ì˜ ì£¼ì œë“¤ì´ ë§ì´ ë“±ì¥í•œë‹¤.
1. implicit neural representation/nerf
nerf(https://arxiv.org/abs/2003.08934)ê°€ 3ì›”ì— ë‚˜ì™”ì„ ë•ŒëŠ” nerfì˜ ìœ„ë ¥ì„ ì•Œì•„ì±„ì§ˆ ëª»í–ˆë‹¤. ì˜¤ ê²°ê³¼ë¬¼ ì¢‹ë„¤! cnn ì—†ì´ mlpë§Œìœ¼ë¡œ íƒœí´í–ˆë‹¤ê³ ? ì‹ ê¸°í•˜ë„¤. ì´ëŸ° ì •ë„. ê·¸ëŸ¬ë‚˜ ì´ì œì™€ì„œ ë³´ë©´ nerfëŠ” ë‰´ëŸ´ ë Œë”ë§ ì—…ê³„ì˜ ì™„ë²½í•œ ëŒ€ì„¸ê°€ ë˜ì—ˆë‹¤ê³  í•´ë„ ì¢‹ì„ ê²ƒ ê°™ë‹¤. ì—­ì‹œ ì¢‹ì€ ì—°êµ¬ë¥¼ ë†“ì¹˜ì§€ ì•Šê³  ì•Œì•„ë³´ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ê¹Šì´ ìƒê°ì„ í•´ë´ì•¼ í•˜ëŠ”ë°...ì¢€ ë„ˆë¬´ ëŒ€ì¶© ìƒê°í–ˆì—ˆë˜ ê²ƒ ê°™ë‹¤. ğŸ˜•
Image Generators with Conditionally-Independent Pixel Synthesis (Ivan Anokhin, Kirill Demochkin, Taras Khakhulin, Gleb Sterkin, Victor Lempitsky, Denis Korzhenkov)
https://arxiv.org/abs/2011.13775
https://arxiv.org/abs/2011.12026 ê³¼ ì•„ì£¼ ì•„ì£¼ ë¹„ìŠ·í•œ ì•„ì´ë””ì–´. weight modulationìœ¼ë¡œ latentì™€ mlpë¥¼ ì—°ê²°í•˜ê³  fourier featureì—ì„œ imageë¡œ ë³€í™˜. ì—¬ê¸°ì„œëŠ” ê° coordinateì— learnable weightë¥¼ ì¶”ê°€ë¡œ ë¶€ì—¬í•˜ê³  multiscale êµ¬ì¡°ëŠ” ë¹ ì§. stylegan2ì™€ ë¹„ìŠ·í•˜ê±°ë‚˜ ê²½ìš°ì— ë”°ë¼ì„œëŠ” ë” ë‚˜ì€ ì„±ëŠ¥.
pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis (Eric R. Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, Gordon Wetzstein)
https://arxiv.org/abs/2012.00926
ì´ë²ˆì—ë„ implicit representationìœ¼ë¡œ ganì˜ generatorë¥¼ êµì²´. ì´ìª½ì€ nerfì— ë” ê°€ê¹ê²Œ hologanì²˜ëŸ¼ 3d ê³µê°„ì—ì„œì˜ ë³€í™˜/ì¹´ë©”ë¼ ìœ„ì¹˜ ë³€í™˜ì— ì´ˆì ì´ ë§ì¶°ì ¸ ìˆìŒ. ê²°ê³¼ì ìœ¼ë¡œëŠ” GRAF(https://arxiv.org/abs/2007.02442)ì™€ ìœ ì‚¬í•˜ê¸´ í•¨. GIRAFFE(https://arxiv.org/abs/2011.12100)ë„ ê·¸ë ‡ê³  neural rendering ì—…ê³„ì˜ í™•ì‹¤í•œ ëŒ€ì„¸.
D-NeRF: Neural Radiance Fields for Dynamic Scenes (Albert Pumarola, Enric Corona, Gerard Pons-Moll, Francesc Moreno-Noguer)
https://arxiv.org/abs/2011.13961
ì‹œê°„ì¶•ì— ëŒ€í•œ interpolationì´ ê°€ëŠ¥í•œ nerf. (https://www.albertpumarola.com/research/D-NeRF/index.html)
Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes (Zhengqi Li, Simon Niklaus, Noah Snavely, Oliver Wang)
https://arxiv.org/abs/2011.13084
ìœ„ì™€ ë§ˆì°¬ê°€ì§€ë¡œ ì‹œê°„ì¶•ì„ í†µí•©í•œ nerf. xyzëŠ” ì´ì œ ë…¸ì¼ ì•„ë‹ˆëƒ? http://www.cs.cornell.edu/~zl548/NSFF
pixelNeRF: Neural Radiance Fields from One or Few Images (Alex Yu, Vickie Ye, Matthew Tancik, Angjoo Kanazawa)
https://arxiv.org/abs/2012.02190
few shot nerf. ì—­ì‹œ ì´ë¯¸ì§€ ì¸ì½”ë”ë¥¼ ë‹¬ì•„ì„œ í•´ê²°í•˜ëŠ” ë°©ì‹. many shot nerf ìˆ˜ì¤€ì˜ ê°•ë ¬í•œ ê²°ê³¼ëŠ” ì•„ì§ ë‚˜ì˜¤ì§€ëŠ” ì•Šì§€ë§Œ ì•ìœ¼ë¡œëŠ”?
Learned Initializations for Optimizing Coordinate-Based Neural Representations (Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P. Srinivasan, Jonathan T. Barron, Ren Ng)
https://arxiv.org/abs/2012.02189
implicit/coordinate representationì´ í…ŒìŠ¤íŠ¸ ì‹œì ì— í•™ìŠµí•´ì•¼ í•˜ëŠ” ì‹œê°„ì´ ê¸°ë‹ˆê¹Œ ë©”íƒ€ëŸ¬ë‹(maml/reptile)ë¡œ ì¢‹ì€ ì´ˆê¸°ê°’ì„ ë¯¸ë¦¬ ë¶€ì—¬í•˜ê³  ì‹œì‘í•˜ê² ë‹¤ëŠ” ë°œìƒ.
2. neural rendering
ë‰´ëŸ´ ë Œë”ë§ ì—…ê³„ì—ì„œ ì¬ë¯¸ìˆëŠ” í˜¹ì€ ì¸ìƒì ì¸ ê²°ê³¼ë“¤ ëª‡ ê°œ.
Full-Resolution Correspondence Learning for Image Translation (Xingran Zhou, Bo Zhang, Ting Zhang, Pan Zhang, Jianmin Bao, Dong Chen, Zhongfei Zhang, Fang Wen)
https://arxiv.org/abs/2012.02047
í¬ì¦ˆ ê°™ì€ ì¡°ê±´(exemplar)ì´ ì£¼ì–´ì§„ ìƒí™©ì—ì„œì˜ img2img. ì¡°ê±´ê³¼ ì†ŒìŠ¤ ì´ë¯¸ì§€ ì‚¬ì´ì˜ correspondenceë¥¼ patchmatchë¡œ ê³„ì‚°í•˜ëŠ” ê²ƒì´ í•µì‹¬. ë‹¤ë¥¸ í˜•íƒœì˜ ë¬¸ì œë¡œë„ í™•ì¥ì´ ê°€ëŠ¥í•œ ì•„ì´ë””ì–´ì¼ì§€ë„?
Animating Pictures with Eulerian Motion Fields (Aleksander Holynski, Brian Curless, Steven M. Seitz, Richard Szeliski)
https://arxiv.org/abs/2011.15128
ì´ë¯¸ì§€ í•œ ì¥ìœ¼ë¡œ ì´ë¯¸ì§€ ë‚´ ìœ ì²´ì˜ íë¦„ì„ ìƒì„±í•´ë‚´ëŠ” ëª¨ë¸. https://eulerian.cs.washington.edu/
Unpaired Image-to-Image Translation via Latent Energy Transport (Yang Zhao, Changyou Chen)
https://arxiv.org/abs/2012.00649
ì˜¤í† ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•´ì„œ ë‘ ë„ë©”ì¸ì„ latent codeë¡œ ë§¤í•‘í•œ ë‹¤ìŒ ì´ ë‘ ë„ë©”ì¸ì˜ codeë¥¼ ë§¤í•‘í•˜ëŠ” ebmì„ í•™ìŠµì‹œì¼œ ë‘ ë„ë©”ì¸ì„ ë§¤í•‘/image translation. ê²°ê³¼ëŠ” ì¬ë¯¸ìˆëŠ”ë° ì—­ì‹œ ì´ëŸ° ì¢…ë¥˜ì˜ img2imgëŠ” ê²°ê³¼ê°€ ì˜ ë‚˜ì˜¨ ê±´ì§€ íŒë‹¨í•˜ëŠ” ê²ƒì´ ì¢€ ì• ë§¤.
3. gan, generative models
2020ë…„ì—ëŠ” ganì—ì„œë„ ê´„ëª©í•  ì§„ì „ì´ ìˆì—ˆê³ , gan ì™¸ì˜ generative modelë“¤ì—ì„œë„ ì—„ì²­ë‚œ ì§„ì „ì´ ìˆì—ˆë‹¤. denoising diffusion, score matching, vae, ì´ë²ˆì—ëŠ” ebmê¹Œì§€! generative modelì´ ë³´í†µ ê·¸ë ‡ë“¯ ìˆ˜í•™ì ìœ¼ë¡œë„ í¥ë¯¸ë¡­ë‹¤. ë¬¼ë¡  sde ì •ë„ê°€ ë‚˜ì˜¤ë©´ ì¢‹ì•„í•˜ëŠ” ë‚˜ê°™ì€ ë‰´ë¹„ ìˆ˜ì¤€ì—ì„œ.
Navigating the GAN Parameter Space for Semantic Image Editing (Anton Cherepkov, Andrey Voynov, Artem Babenko)
https://arxiv.org/abs/2011.13786
gan ì´ë¯¸ì§€ í¸ì§‘ ë°©ë²•ì¸ë°...ê¸°ì¡´ì˜ ë°©ë²•ë“¤ì„ ì‚¬ìš©í•˜ì§€ë§Œ ê°€ì¥ í° ì°¨ì´ëŠ” latent codeê°€ ì•„ë‹ˆë¼ generatorì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë³€í™˜í•œë‹¤ëŠ” ê²ƒ. ì½” ê¸¸ì´ ë°”ê¾¸ê¸°ë‚˜ ë±€íŒŒì´ì–´í™” ê°™ì€ ë³€í™˜ì„ generatorì˜ íŒŒë¼ë¯¸í„° ê³µê°„ì—ì„œ ì°¾ì•„ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ê²Œ ì¢€ ê¸°ë¬˜í•¨. https://github.com/yandex-research/navigan
Self-labeled Conditional GANs (Mehdi Noroozi)
https://arxiv.org/abs/2012.02162
ë ˆì´ë¸” ì—†ì´ conditional gan íŠ¸ë ˆì´ë‹. ê²°ê³¼ì ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë“ˆì´ ë¶™ì–´ì„œ ê°™ì´ í•™ìŠµë˜ëŠ” ë°©ì‹ì¸ë°...tunit (https://arxiv.org/abs/2006.06500) ì•„ë…€!?
Omni-GAN: On the Secrets of cGANs and Beyond (Peng Zhou, Lingxi Xie, Bingbing Ni, Qi Tian)
https://arxiv.org/abs/2011.13074
auxillary classifier, projection discriminatorë¥¼ ëŒ€ì²´í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ conditional gan. class labelê³¼ adversarial lossë¥¼ ë” ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°í–ˆë‹¤ëŠ” ëŠë‚Œì¸ë°...
Refining Deep Generative Models via Wasserstein Gradient Flows (Abdul Fatir Ansari, Ming Liang Ang, Harold Soh)
https://arxiv.org/abs/2012.00780
í•œë™ì•ˆ ë‚˜ì™”ë˜ discriminatorë¥¼ ì‚¬ìš©í•œ ìƒ˜í”Œ ê°œì„ . f-divergenceì˜ gradient flowë¥¼ ìƒê°í•œ ë‹¤ìŒ sdeì™€ ì—°ê²°í•´ì„œ discriminatorë¥¼ ë¼ì›Œë„£ëŠ” ë°©ì‹ìœ¼ë¡œ ìœ ë„. ê½¤ ìƒí¼í•˜ë‹ˆ í•œ ë²ˆ ë³´ì…”ë„.
How to train your conditional GAN: An approach using geometrically structured latent manifolds (Sameera Ramasinghe, Moshiur Farazi, Salman Khan, Nick Barnes, Stephen Gould)
https://arxiv.org/abs/2011.13055
conditional ganì—ì„œ diversityê°€ ë–¨ì–´ì§€ëŠ”(mode collapse) ì´ìœ . latent mainfoldì˜ í° ì˜ì—­ë“¤ì„ singular pointë¡œ ë§¤í•‘í•˜ê¸° ë•Œë¬¸. generatorê°€ latent manifoldì™€ generatorì˜ output image manifold ì‚¬ì´ì˜ homeomorphismì´ ë˜ë„ë¡ í•™ìŠµ ê³¼ì •ì„ ê°œì„ í•˜ë ¤ëŠ” ì•„ì´ë””ì–´. ìƒë‹¹íˆ í¥ë¯¸ë¡œìš´ ê°œì„ ì¸ ë“¯. ë¦¬ë§Œ ê¸°í•˜ ë§› ì¢€ ë³¼ë˜?
Score-Based Generative Modeling through Stochastic Differential Equations (Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole)
https://arxiv.org/abs/2011.13456
openreviewì— ì˜¬ë¼ì™”ì—ˆë˜ denoising diffusionê³¼ score based modelì„ sdeë¥¼ ì‚¬ìš©í•´ í†µí•©í•œ ì—°êµ¬. ì €ìë“¤ì´ ì§±ì§±í–ˆì—ˆë„¤.
Improved Contrastive Divergence Training of Energy Based Models (Yilun Du, Shuang Li, Joshua Tenenbaum, Igor Mordatch)
https://arxiv.org/abs/2012.01316
IGEBM(https://arxiv.org/abs/1903.08689) ì €ìë“¤ì´ ë‹¤ì‹œ ì¶œë™! contrastive-divergenceì—ì„œ ê°„ê³¼ë˜ì–´ì™”ë˜ termë¥¼ ë‹¤ì‹œ ì‚´ë¦¬ê³  ìƒ˜í”Œë§ ê³¼ì • ê°œì„  & ë©€í‹°ìŠ¤ì¼€ì¼í™”. generative model ì—…ê³„ì˜ ê²½ìŸì´ ë§¤ìš° ê²©ë ¬.
SplitNet: Divide and Co-training (Shuai Zhao, Liguang Zhou, Wenxiao Wang, Deng Cai, Tin Lun Lam, Yangsheng Xu)
https://arxiv.org/abs/2011.14660
ëª¨ë¸ scalingì—ëŠ” ê¹Šì´, í­, ì…ë ¥ í¬ê¸° ë§ê³  ëª¨ë¸ì˜ ìˆ˜ë„ í¬í•¨ì‹œí‚¬ ìˆ˜ ìˆì§€ ì•Šì€ê°€ í•˜ëŠ” ì•„ì´ë””ì–´. ì‘ì€ ëª¨ë¸ ì—¬ëŸ¬ ê°œë¥¼ ê°™ì´ í•™ìŠµì‹œí‚¤ê³  ì•™ìƒë¸”.
4. self supervised learning
ì´ëŸ¬ë‹ˆ ì €ëŸ¬ë‹ˆ í•´ë„ ì˜¬í•´ì˜ ê°€ì¥ í° ì§„ì „ì„ ë‹¨ í•˜ë‚˜ë§Œ ê¼½ìœ¼ë¼ë©´ ì—­ì‹œ contrastive learningì„ ìœ„ì‹œí•œ self supervisionì¼ ê²ƒì´ë‹¤. ë°ì´í„° ë¬¸ì œë¥¼ ë°ì´í„°ë¥¼ ë” íˆ¬ì…í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ê²°í•˜ëŠ” ê²ƒ ê°™ì€ ëŠë‚Œì´ë¼ ì¢€ ê½ê¸°ê½ê¸°í•˜ê¸´ í•˜ì§€ë§Œ ì–´ì¨Œë“  í•œë™ì•ˆ, í˜¹ì€ ìƒê°ë³´ë‹¤ ì˜¤ë«ë™ì•ˆ ì¤‘ìš”í•œ ë„êµ¬ê°€ ë  ë“¯ í•˜ë‹¤. ì—°êµ¬ìê°€ ì•„ë‹ˆë¼ ì—”ì§€ë‹ˆì–´ì˜ ì…ì¥ì—ì„œë„ ë„êµ¬ìƒìì— í•˜ë‚˜ ì¥ì°©í•´ì•¼ í•˜ì§€ ì•Šì„ì§€?
How Well Do Self-Supervised Models Transfer? (Linus Ericsson, Henry Gouk, Timothy M. Hospedales)
https://arxiv.org/abs/2011.13377
self supervised ì•Œê³ ë¦¬ì¦˜ì˜ ê°ì¢… ê³¼ì œì— ëŒ€í•œ transfer ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬. ê³¼ì œ ì¢…ë¥˜ë§ˆë‹¤ ì¢‹ì€ ì•Œê³ ë¦¬ì¦˜ì´ ë‹¤ë¥´ê¸´ í•œë°...ì „ë°˜ì ìœ¼ë¡œëŠ” byolì´ ëŒ€ì²´ë¡œ ê´œì°®ì€ ë“¯.
Beyond Single Instance Multi-view Unsupervised Representation Learning (Xiangxiang Chu, Xiaohang Zhan, Xiaolin Wei)
https://arxiv.org/abs/2011.13356
self supervised learningì—ì„œ ì´ë¯¸ì§€ ìƒ˜í”Œì„ (cutmix ê°™ì´) ë¯¹ìŠ¤í•´ì„œ ë¯¹ìŠ¤ì— ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìƒ˜í”Œë“¤ì„ spurious positive pairë¡œ ì‚¬ìš©.
Can Temporal Information Help with Contrastive Self-Supervised Learning? (Yutong Bai, Haoqi Fan, Ishan Misra, Ganesh Venkatesh, Yongyi Lu, Yuyin Zhou, Qihang Yu, Vikas Chandra, Alan Yuille)
https://arxiv.org/abs/2011.13046
ì˜ìƒì— ëŒ€í•œ self supervised learning. ì‹œê°„ì— ëŒ€í•œ augmentationë§Œìœ¼ë¡œëŠ” ë„ì›€ì´ ì•ˆ ë˜ê³  ì´ augmentationì— ëŒ€í•´ ì¶”ê°€ì ì¸ ê³¼ì œë¥¼ ë¶™ì—¬ì¤˜ì•¼ í•œë‹¤ëŠ” ê²°ë¡ . (ì˜ìƒì„ ê±°ê¾¸ë¡œ ëŒë¦¬ê³  ìˆë‹¤ëŠ” ê²ƒì„ ë§ì¶”ê²Œ í•œë‹¤ë“ ì§€.)
Self-EMD: Self-Supervised Object Detection without ImageNet (Songtao Liu, Zeming Li, Jian Sun)
https://arxiv.org/abs/2011.13677
detectionì— ì í•©í•œ self supervision níƒ„. byol ê¸°ë°˜ìœ¼ë¡œ global poolingì„ ë¹¼ë²„ë¦¬ê³  feature map ì‚¬ì´ì˜ earth mover's distanceë¥¼ similarityë¡œ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì´ í•µì‹¬.
Towards Good Practices in Self-supervised Representation Learning (Srikar Appalaraju, Yi Zhu, Yusheng Xie, IstvÃ¡n FehÃ©rvÃ¡ri)
https://arxiv.org/abs/2012.00868
self supervisionì—ì„œ ì¤‘ìš”í•œ ì„ íƒë“¤ì— ëŒ€í•œ ë¶„ì„. ì‚¬ì‹¤ìƒ MoCo v2ì— ëŒ€í•œ ablation ë° ë¶„ì„. deep image priorë¡œ mlpì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•œ ê²ƒì´ ê½¤ ì¬ë¯¸ìˆìŒ.
SelfText Beyond Polygon: Unconstrained Text Detection with Box Supervision and Dynamic Self-Training (Weijia Wu, Enze Xie, Ruimao Zhang, Wenhai Wang, Guan Pang, Zhen Li, Hong Zhou, Ping Luo)
https://arxiv.org/abs/2011.13307
ë¹„êµì  ì €ë ´í•œ ë°•ìŠ¤ ë ˆì´ë¸”ì„ ë¦¬íŒŒì¸í•´ì„œ í´ë¦¬ê³¤ ë ˆì´ë¸”ì˜ íš¨ê³¼ë¥¼ ë‚´ë³´ë ¤ëŠ” ì‹œë„. ìš”ì¦˜ ê°™ì€ pseudo labelì˜ ì‹œëŒ€ì—ëŠ” ì¶©ë¶„íˆ ê°€ëŠ¥í•œ ë°©ë²•ì¸ ê²ƒ ê°™ê¸°ë„ í•˜ê³ .
Weakly-Supervised Arbitrary-Shaped Text Detection with Expectation-Maximization Algorithm (Mengbiao Zhao, Wei Feng, Fei Yin, Xu-Yao Zhang, Cheng-Lin Liu)
https://arxiv.org/abs/2012.00424
ì´ìª½ë„ ë°•ìŠ¤ ë ˆì´ë¸”ì„ ì‚¬ìš©í•´ì„œ ì„±ëŠ¥ì„ ê°œì„ í•˜ë ¤ëŠ” ì‹œë„. ê²°ê³¼ë„ ì¬ë¯¸ìˆê³ ...ì‹¤í—˜ì— ì‚¬ìš©í•œ centernet (keypoint triplet ì•„ë‹˜ ã…)ê³¼ deep snakeë¥¼ ë¶™ì¸ ëª¨ë¸ë„ í¥ë¯¸ë¡œìš´ ë“¯.
Unsupervised part representation by Flow Capsules (Sara Sabour, Andrea Tagliasacchi, Soroosh Yazdani, Geoffrey E. Hinton, David J. Fleet)
https://arxiv.org/abs/2011.13920
ìº¡ìŠ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ì—ì„œ ì´ë¯¸ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œë“¤ì„ ë¶„í•´í•˜ë„ë¡ í•™ìŠµ. ì˜ìƒì—ì„œì˜ ì›€ì§ì„ì„ ì´ self supervisionì˜ ì£¼ìš”í•œ ë‹¨ì„œë¡œ í™œìš©. ì¸ê°„ì€ ê³ ì •ëœ ì˜ìƒì„ ë³´ëŠ” ê²½ìš°ê°€ ì‚¬ì‹¤ìƒ ì—†ê¸° ë•Œë¬¸ì— ì˜ìƒì„ í™œìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì€ ë°©í–¥ì´ ë  ìˆ˜ ìˆë‹¤ê³  ìƒê°.
5. transformer & vision
ì‚¬ì‹¤ ì´ë¯¸ì§€ì— ì²˜ë¦¬ì— attentionì„ ê²°í•©í•œ ê²ƒì€ í•˜ë£¨ ì´í‹€ ì¼ì´ ì•„ë‹ˆê¸´ í•œë° ViT(https://arxiv.org/abs/2010.11929) ì´í›„ë¡œ ì¢€ ë” ê´€ì‹¬ì„ ë°›ê³  ìˆì§€ ì•Šì€ì§€. ì•„ì§ê¹Œì§€ëŠ” ì•„ì£¼ íš¨ìœ¨ì ì´ë¼ëŠ” ìƒê°ì€ ë“¤ì§€ ì•Šì§€ë§Œ ì•ìœ¼ë¡œëŠ” ë˜ ì–´ë–¨ì§€.
General Multi-label Image Classification with Transformers (Jack Lanchantin, Tianlu Wang, Vicente Ordonez, Yanjun Qi)
https://arxiv.org/abs/2011.14027
íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ multilabel classification. masked labelì„ ì˜ˆì¸¡í•˜ë„ë¡ í•˜ëŠ” ë°©ì‹. ë ˆì´ë¸”ì´ ë¶€ë¶„ì ìœ¼ë¡œ ì£¼ì–´ì¡Œì„ ë•Œ í˜¹ì€ ì¶”ê°€ì ì¸ ë ˆì´ë¸”ì´ ì£¼ì–´ì¡Œì„ ë•Œ ì´ ë ˆì´ë¸” ì •ë³´ë¥¼ ì‚¬ìš©í•´ì„œ ì¶œë ¥ ê²°ê³¼ë¥¼ ê°œì„ í•  ìˆ˜ ìˆëŠ” ê²ƒì„ ëª©í‘œë¡œ ì„¤ì •. í¥ë¯¸ë¡œìš´ ê³¼ì œì¸ ë“¯.
Pre-Trained Image Processing Transformer (Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu, Chao Xu, Wen Gao)
https://arxiv.org/abs/2012.00364
íŠ¸ëœìŠ¤í¬ë¨¸ë¥¼ ì´ë¯¸ì§€ denoising, deraining, superresolution, contrastive learningìœ¼ë¡œ í”„ë¦¬íŠ¸ë ˆì´ë‹í•œ ë‹¤ìŒ íŒŒì¸íŠœë‹. ì´ê±´ ëŒ€ì²´...ë­”ê°€...ë­”ê°€ ì¼ì–´ë‚˜ê³  ìˆìŒ.
Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs (Emanuele Bugliarello, Ryan Cotterell, Naoaki Okazaki, Desmond Elliott)
https://arxiv.org/abs/2011.15124
vision & language bert ëª¨ë¸ë“¤ì„ í†µí•©ì ì¸ í”„ë ˆì„ì›Œí¬ í•˜ì—ì„œ ë¹„êµ. ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì´ ë¹„ìŠ·ë¹„ìŠ·í•˜ë‹¤ëŠ” ê²ƒ, initializationì— ë”°ë¥¸ ê²°ê³¼ì˜ ë¶„ì‚°ì´ í¬ë‹¤ëŠ” ê²ƒ, ì„ë² ë”© ë ˆì´ì–´ë¥¼ ì–´ë–»ê²Œ ì„¸íŒ…í•˜ëŠ”ê°€ê°€ ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬.
6. nlp
nlp ì—…ê³„ ì¶œì‹ (?)ì´ë¼ê³  ìì²˜í•˜ëŠ”ë° nlpì— ëŒ€í•´ì„œ í•  ë§ì´ ë³„ë¡œ ì—†ë‹¤. ì‚¬ì‹¤ self supervisionìœ¼ë¡œ ì¬ì‘ë…„ ~ ì‘ë…„ì— ì´ë¯¸ ëŒ€ë°•ì„ í„°ëœ¨ë ¤ì„œ ê·¸ëŸ° ê²ƒ ê°™ê¸°ë„ í•˜ê³ .
Learning from others' mistakes: Avoiding dataset biases without modeling them (Victor Sanh, Thomas Wolf, Yonatan Belinkov, Alexander M. Rush)
https://arxiv.org/abs/2012.01300
ë°ì´í„°ì…‹ì˜ biasë¥¼ ë³´ì™„í•˜ëŠ” ë°©ë²•. weak learnerê°€ biasë¥¼ í™œìš©í•œë‹¤ëŠ” ì ì„ ì´ìš©í•´ weak learnerì„ í•™ìŠµì‹œí‚¤ê³ , ë©”ì¸ ëª¨ë¸ì— weak learnerë¥¼ ì—°ê²°í•´ product of expertsë¡œ í•™ìŠµì‹œì¼œì„œ ë©”ì¸ ëª¨ë¸ì´ weak learnerì˜ ë¬¸ì œë¥¼ ë³´ì™„í•˜ë„ë¡ ë§Œë“¦.
How Can We Know When Language Models Know? (Zhengbao Jiang, Jun Araki, Haibo Ding, Graham Neubig)
https://arxiv.org/abs/2012.00955
lm ê¸°ë°˜ qa ëª¨ë¸ì—ì„œ ë‚˜ì˜¤ëŠ” ë‹µì„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ”ê°€? ê²°êµ­ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë¬¸ì œê°€ ë¨. ë…¼ë¬¸ì—ì„œ ì œì•ˆí•œ ë°©ë²•ê³¼ ì—¬ëŸ¬ ê¸°ì¡´ ë°©ë²•ë“¤ì„ ì‚¬ìš©í•´ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ì ìš©.
StructFormer: Joint Unsupervised Induction of Dependency and Constituency Structure from Masked Language Modeling (Yikang Shen, Yi Tay, Che Zheng, Dara Bahri, Donald Metzler, Aaron Courville)
https://arxiv.org/abs/2012.00857
constituencyì™€ dependency êµ¬ì¡°ë¥¼ ëª¨ë‘ ì¶”ì¶œí•˜ëŠ” unsupervised parsing. íŒŒì„œ ëª¨ë“ˆë¡œ dependency êµ¬ì¡°ë¥¼ ì¶”ì¶œí•œ ë‹¤ìŒ self attentionì— ì£¼ì…í•˜ê³  mlmìœ¼ë¡œ í•™ìŠµ.
Progressively Stacking 2.0: A Multi-stage Layerwise Training Method for BERT Training Speedup (Cheng Yang, Shengnan Wang, Chao Yang, Yuechuan Li, Ru He, Jingqiao Zhang)
https://arxiv.org/abs/2011.13635
bert í”„ë¦¬íŠ¸ë ˆì´ë‹ ì†ë„ ê°œì„ . ë ˆì´ì–´ë¥¼ í•˜ë‚˜ì”© ìŒ“ì•„ê°€ë©´ì„œ ìƒˆë¡œ ì¶”ê°€í•œ ë ˆì´ì–´ë§Œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹. í•™ìŠµ ì‹œê°„ì„ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„. electra ê°™ì€ ëª¨ë¸ê³¼ ê²°í•©í•  ìˆ˜ëŠ” ì—†ì„ê¹Œ ì‹¶ê¸°ë„ í•˜ê³ .
7. detr & image recognition
ë˜í•œ ì˜¬í•´ì˜ í° í˜ì‹ , detrì„ ìœ„ì‹œí•œ image recognition ë¬¸ì œì˜ end2end í•™ìŠµ. ì‚¬ì‹¤ object detectionì´ë¼ëŠ” ë¬¸ì œ ìì²´ì—ì„œëŠ” ì•„ì£¼ í° ë©”ë¦¬íŠ¸ê°€ ìˆë‚˜ í•˜ëŠ” ìƒê°ë„ í•˜ì§€ë§Œ, ë³µì¡í•œ ë¬¸ì œë¡œ ë„˜ì–´ê°€ë©´ ì´ end2end í•™ìŠµì˜ ê°•ì ê³¼ ìš°ì•„í•¨ì´ ë” ì˜ ë“œëŸ¬ë‚˜ëŠ” ë“¯ ì‹¶ë‹¤. lossë¥¼ ì–´ë–»ê²Œ ë¶€ì—¬í•  ê²ƒì¸ê°€ ìì²´ê°€ ì–´ë ¤ìš´ ë¬¸ì œë“¤ì— ëŒ€í•´ì„œ ì¢‹ì€, ê·¸ë¦¬ê³  ìƒê° ì´ìƒìœ¼ë¡œ ì¼ë°˜ì ì¸ í•´ë²•ì„ ì œê³µí•˜ê³  ìˆë‹¤. í•™ìŠµ ì–´ë µê³  ë¬´ê²ê³  ê°™ì€ ë¬¸ì œë“¤ì´ ìˆì§€ë§Œ ë¬´ì„œìš´ ë””í…ì…˜-í¼ìŠ¨ë“¤ì´ ì¶œë™í•´ì„œ ì´ë¯¸ ì§„ì „ì„ ë³´ì—¬ì£¼ê³  ìˆê¸° ë•Œë¬¸ì— ê³§ í° ë¬¸ì œê°€ ì•„ë‹ˆê²Œ ë ì§€ë„.
ê·¸ë ‡ì§€ë§Œ ì¢€ ì „í†µì (?)ì¸ ì—…ê³„ì—ë„ ì¬ë¯¸ìˆëŠ” ê²°ê³¼ë“¤ì€ ë§ì´ ë‚˜ì™”ë‹¤. BlendMask(https://arxiv.org/abs/2001.00309), CondInst(https://arxiv.org/abs/2003.05664), SOLOv2(https://arxiv.org/abs/2003.10152), Axial-DeepLab(https://arxiv.org/abs/2003.07853), DetectoRS(https://arxiv.org/abs/2006.02334), Sibling Head(https://arxiv.org/abs/2003.07540), See-Saw Loss(https://arxiv.org/abs/2008.10032) ë“±ë“±ë“±. COCO mAP 50ì„ ë„˜ê¸°ëŠ” ê²ƒì´ ë””í…í„°ì˜ ê¸°ë³¸ ì†Œì–‘ì´ ëœ í•´ì´ê¸°ë„ í•˜ì§€ ì•Šë‚˜ ì‹¶ë‹¤.
MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers (Huiyu Wang, Yukun Zhu, Hartwig Adam, Alan Yuille, Liang-Chieh Chen)
https://arxiv.org/abs/2012.00759
ì•µì»¤ë„ ì¤‘ì‹¬ì ë„ nmsë„ merge ìŠ¤í…ë„ ë°•ìŠ¤ë„ ì—†ë‹¤! ë§ˆìŠ¤í¬ì˜ í´ë˜ìŠ¤ ë ˆì´ë¸”ê³¼ dice lossë¡œ ë§ˆìŠ¤í¬ë¥¼ ë§¤ì¹­í•´ì„œ í•™ìŠµ. argmax ë‘ ë²ˆë§Œìœ¼ë¡œ í´ë˜ìŠ¤ ë ˆì´ë¸”ê³¼ ë§ˆìŠ¤í¬ idë¥¼ ë½‘ì•„ë‚¼ ìˆ˜ ìˆìŒ.
End-to-End Video Instance Segmentation with Transformers (Yuqing Wang, Zhaoliang Xu, Xinlong Wang, Chunhua Shen, Baoshan Cheng, Hao Shen, Huaxia Xia)
https://arxiv.org/abs/2011.14503
detrì‹ì˜ ì˜ìƒ instance segmentation. instance sequenceë¥¼ ë§¤ì¹­í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ end2end í•™ìŠµ. ë”°ë¼ì„œ instance segmentationê³¼ trackingì„ end2endë¡œ ê¹¨ë—í•˜ê²Œ í†µí•©. ì—¬ê¸°ê¹Œì§€ ì˜¤ë‹ˆ detrì˜ ì¥ì ì´ ë” ì˜ ë“œëŸ¬ë‚˜ëŠ” ë“¯.
Fully Convolutional Networks for Panoptic Segmentation (Yanwei Li, Hengshuang Zhao, Xiaojuan Qi, Liwei Wang, Zeming Li, Jian Sun, Jiaya Jia)
https://arxiv.org/abs/2012.00720
dynamic convolution ê¸°ë°˜ panoptic segmentation. kernel generationì´ instance segmentationì˜ ëŒ€ì„¸.
Single-shot Path Integrated Panoptic Segmentation (Sukjun Hwang, Seoung Wug Oh, Seon Joo Kim)
https://arxiv.org/abs/2012.01632
ì´ìª½ë„ dynamic convë¥¼ ì‚¬ìš©í•œ panoptic segmentation. ì–´ì©Œë‹¤ë³´ë‹ˆ ì—…ê³„ê°€ (dynamic conv ê°™ì€) ì¢€ ì „í†µì ì¸ ì ‘ê·¼ê³¼ detrë¥¼ ìœ„ì‹œí•œ ì‹ í¥ end2end ì ‘ê·¼ìœ¼ë¡œ í•œ íŒ ë¶™ëŠ” ê²ƒ ê°™ì€ ëŠë‚Œì¸ë°...ì•ìœ¼ë¡œ ì–´ëŠìª½ì´ ë” í˜ì„ ë°›ê²Œ ë ì§€?
The Devil is in the Boundary: Exploiting Boundary Representation for Basis-based Instance Segmentation (Myungchul Kim, Sanghyun Woo, Dahun Kim, In So Kweon)
https://arxiv.org/abs/2011.13241
basis ê¸°ë°˜ instance segmentationì— boundaryì— í•´ë‹¹í•˜ëŠ” basisë¥¼ ì¶”ê°€. mAP 1 ì •ë„ì˜ íš¨ê³¼.
Sparse R-CNN: End-to-End Object Detection with Learnable Proposals (Peize Sun, Rufeng Zhang, Yi Jiang, Tao Kong, Chenfeng Xu, Wei Zhan, Masayoshi Tomizuka, Lei Li, Zehuan Yuan, Changhu Wang, Ping Luo)
https://arxiv.org/abs/2011.12450
rpnìœ¼ë¡œ ì´ë¯¸ì§€ë³„ proposalì„ ì¶”ì¶œí•˜ëŠ” ê²Œ ì•„ë‹ˆë¼ ë°ì´í„°ì…‹ ì „ì²´ì— ëŒ€í•´ì„œ ê³ ì •ëœ proposalì˜ ì§‘í•©ì„ ë§Œë“¤ê³  ì´ proposalì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•. ê³ ì •ê´€ë…ì— ëŒ€í•œ ì‹ ë°•í•œ íƒ€íŒŒì´ê¸´ í•œë° ì •ë§ ì´ë˜ë„ ê´œì°®ì€ê°€ ì‹¶ê¸°ëŠ” í•¨.
Dynamic Feature Pyramid Networks for Object Detection (Mingjian Zhu, Kai Han, Changbin Yu, Yunhe Wang)
https://arxiv.org/abs/2012.00779
fpn ê°œì„  1. ì•½ê°„ https://arxiv.org/abs/2005.03101 ê°™ì€ fpnì— ëŒ€í•œ multiscale aggregationì— ê²Œì´íŠ¸ë¥¼ ë‹¬ì•„ì„œ ì¶”ë¡  ê³¼ì •ì—ì„œ ì—°ì‚°ì„ ê±´ë„ˆë›¸ ìˆ˜ ìˆê²Œ ë§Œë“  ê²ƒ ê°™ì€ fpn. ë””í…í„°ëŠ” ì˜ì›íˆ íŠœë‹ ë–¡ë°¥ì„ ì œê³µí•˜ëŠ” ë“¯.
Dual Refinement Feature Pyramid Networks for Object Detection (Jialiang Ma, Bin Chen)
https://arxiv.org/abs/2012.01733
fpn ê°œì„  2. ì´ìª½ì€ offsetì„ ì‚¬ìš©í•œ deformationê³¼ channel attentionìœ¼ë¡œ low res-high res ê²°í•©ì„ ê°œì„ í•´ë³´ê² ë‹¤ëŠ” ë°œìƒ.
Parallel Residual Bi-Fusion Feature Pyramid Network for Accurate Single-Shot Object Detection (Ping-Yang Chen, Ming-Ching Chang, Jun-Wei Hsieh, Yong-Sheng Chen)
https://arxiv.org/abs/2012.01724
fpn ê°œì„  3. ì´ìª½ë„ bifpn êµ¬ì¡°ì— ëŒ€í•œ ê°œì„ .
Class-agnostic Object Detection (Ayush Jaiswal, Yue Wu, Pradeep Natarajan, Premkumar Natarajan)
https://arxiv.org/abs/2011.14204
í´ë˜ìŠ¤ ìƒê´€ ì—†ì´ ê°ì²´ ê²€ì¶œë§Œ í•´ë³´ìëŠ” ë°œìƒ. ê·¸ëŸ¬ë‹ˆê¹Œ í•™ìŠµì…‹ì— ì—†ëŠ” í´ë˜ìŠ¤ì˜ ê°ì²´ë“¤ë„ ê²€ì¶œí•´ë‚´ëŠ” ê²ƒì´ ì¤‘ìš”í•œ ë¬¸ì œê°€ ë¨. ì¼ë‹¨ ê°ì²´ë¥¼ ê²€ì¶œí•´ë‚´ê³  ë´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ë§ì´ ìˆì„ í…Œë‹ˆ ì‹¤ìš©ì ì¸ ë¬¸ì œê°€ ì•„ë‹ê¹Œ í•˜ëŠ” ìƒê°.
8. ê·¸ ì™¸
Truly shift-invariant convolutional neural networks (Anadi Chaman (1), Ivan DokmaniÄ‡ (2) ((1) University of Illinois at Urbana-Champaign, (2) University of Basel))
https://arxiv.org/abs/2011.14214
shift consistencyë¥¼ ë¶€ì—¬í•˜ê¸° ìœ„í•œ ì‹ ë°•í•œ ë°©ë²•. circular paddingê³¼ ê°™ì´ ì‚¬ìš©í•˜ë©´ 100% consistencyê°€ ì°í˜.
Batch Normalization with Enhanced Linear Transformation (Yuhui Xu, Lingxi Xie, Cihang Xie, Jieru Mei, Siyuan Qiao, Wei Shen, Hongkai Xiong, Alan Yuille)
https://arxiv.org/abs/2011.14150
batch normì˜ affine transformì„ depthwise convë¡œ ëŒ€ì²´. 1x ìŠ¤ì¼€ì¥´ì—ì„œ 2 mAP ì •ë„ì˜ í–¥ìƒ. latencyëŠ” ìƒê°ë³´ë‹¤ëŠ” í¬ì§€ ì•Šì€ ê²ƒ ê°™ì€ë° ì‹¤ì œë¡œ ì–´ë–¨ì§€.
Image Quality Assessment for Perceptual Image Restoration: A New Dataset, Benchmark and Metric (Jinjin Gu, Haoming Cai, Haoyu Chen, Xiaoxing Ye, Jimmy Ren, Chao Dong)
https://arxiv.org/abs/2011.15002
ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€ ë°ì´í„°ì…‹. ê¸°ì¡´ì˜ ì—¬ëŸ¬ ì™œê³¡ë“¤ ë¿ë§Œ ì•„ë‹ˆë¼ gan ê¸°ë°˜ ëª¨ë¸ë“¤ì—ì„œ ë°œìƒí•˜ëŠ” ì™œê³¡ë“¤ë„ í¬í•¨ì‹œì¼°ë‹¤ëŠ” ê²ƒì´ íŠ¹ì§•. ë°ì´í„°ì…‹ ë§Œë“œëŠ” ì‚¬ëŒë“¤ì—ê²ŒëŠ” ëŠ˜ ê²½ì˜ë¥¼.
FBWave: Efficient and Scalable Neural Vocoders for Streaming Text-To-Speech on the Edge (Bichen Wu, Qing He, Peizhao Zhang, Thilo Koehler, Kurt Keutzer, Peter Vajda)
https://arxiv.org/abs/2011.12985
nonautoregressive flowì™€ autoregressive flowë¥¼ ë¶™ì¸ í˜•íƒœì˜ vocoder. quantizationí•˜ê³  ê°¤ëŸ­ì‹œ S8ì— ì˜¬ë ¸ë”ë‹ˆ real-time factor 0.7 ì •ë„ê°€ ë‚˜ì™”ë‹¤ê³ .
Field of Junctions (Dor Verbin, Todd Zickler)
https://arxiv.org/abs/2011.13866
ê²½ê³„ì„  ê²€ì¶œ ì•Œê³ ë¦¬ì¦˜. í¥ë¯¸ë¡œìš´ë°...ì˜¤ë˜ê±¸ë¦¼. (250x250px ì´ë¯¸ì§€ì— ëŒ€í•´ V100ì—ì„œ 2ë¶„.)
Streaming end-to-end multi-talker speech recognition (Liang Lu, Naoyuki Kanda, Jinyu Li, Yifan Gong)
https://arxiv.org/abs/2011.13148
ì—­ì‹œë‚˜ rnn-t ê¸°ë°˜. efficient rnn-t êµ¬í˜„ì´ í•„ìš”í•˜ë‹¤...!

#review