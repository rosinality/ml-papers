https://arxiv.org/abs/2002.05202

GLU Variants Improve Transformer (Noam Shazeer)

GPT-2 이후로 모두가 궁금해했을 것 같은 트랜스포머에서 GELU가 ReLU보다 얼마나 나은가에 대한 발전형 리포트. 결론: GLU가 좀 더 재밌는 것 같다.

#transformer #activation