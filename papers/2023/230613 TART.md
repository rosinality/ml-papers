https://arxiv.org/abs/2306.07536

TART: A plug-and-play Transformer module for task-agnostic reasoning (Kush Bhatia, Avanika Narayan, Christopher De Sa, Christopher Ré)

llm 같은 모델을 사용해 새로운 과제를 수행하게 하는 방법인데...아이디어가 굉장히 신기하네요. in context learning처럼 데이터와 레이블 페어에 대한 임베딩을 사용해 레이블을 예측하게 하는데, 실제 데이터를 사용하는 대신 gaussian random noise를 입력으로 주고 레이블을 logistic regression으로 예측하게 하는 방법을 사용합니다. 즉 완전히 synthetic한 데이터로 추가 모듈을 학습하고, 테스트 시에는 실제 텍스트에 대해 생성한 임베딩을 입력으로 줘서 각 과제에 사용하는 방식이네요. in context learning과 finetuning의 장점을 결합한다는 제안이네요.

#in_context_learning 