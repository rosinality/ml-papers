https://arxiv.org/abs/2307.09782

ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats (Xiaoxia Wu, Zhewei Yao, Yuxiong He)

int8 대신 fp8 activation을 쓰고, 아예 weight도 fp4를 쓰는 것도 괜찮을 것 같은데? 라는 결과네요. H100이 있다면 할 수 있는 일...

#quantization 