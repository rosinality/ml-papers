https://arxiv.org/abs/2306.15658

CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy within a \$10,000 Budget; An Extra \$4,000 Unlocks 81.8% Accuracy (Xianhang Li, Zeyu Wang, Cihang Xie)

CLIPA(https://arxiv.org/abs/2305.07017) 의 아이디어는 큰 모델일수록 이미지/텍스트 토큰을 날려서 길이를 줄여도 성능 저하가 적다는 것이었는데...이걸 규모를 키워서 실험해봤군요.

#vision-language #contrastive_learning #multimodal 