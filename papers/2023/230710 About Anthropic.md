처음에 Anthropic이라는 회사가 있고, AI Safety를 주로 다루는 회사라고 들었을 때는 떨떠름하게 생각했었다. OpenAI가 GPT-2나 GPT-3에 대해서 공개하기에는 너무 위험한 모델이라고 말했던 식의 호들갑처럼 느껴졌었던 것 같다. AI/ML이 그렇게 위험한 것이었던가? (물론 그때도 AI의 위험성에 대한 논의들은 있었지만, 현재의 alignment와는 결이 달랐다고 할 수 있을 것이다.)

그렇지만 지금은 Anthropic의 논문을 가장 주의 깊게 읽게 된다. OpenAI 외에 그래도 지금 시점에서 참고해야할만한 주제들에 대해 가장 많이 공개해주었으므로.

그와 함께 느껴지는 것은 짙은 열패감. 아마 작년까지만 해도, 규모나 기술에서 물론 OpenAI, 구글 등등이 뛰어나다고 생각하긴 했지만, 결과적으로 그들의 접근이 더 옳았다는 것을 인정하게 되긴 했지만, 내가 알 수 없는 수준에 있다는 생각은 하지 않았던 듯 하다. 물론 그건 일부 논문으로 결과들이 공개되었고 어쨌든 그 논문을 읽고 이해할 수 있다는 것에서 온 착각이었을 것이다.

그렇지만 지금에야 깨닫게 되는 것은 단순히 겉으로 보이는 규모 뿐만 아니라, 경험과 지식에서, 통찰 모두에서 엄청난 격차가 있다는 것. OCR을 하던 시절에는 OCR에서는 어디 밀리지 않는다고 진심으로 믿고 있었기에 느껴보지 않았던 감각을 지금에야 깨닫게 된다. 지금도 그렇게 생각하고 있고.

주절주절 길게 썼지만 간단히 요약하자면 그들이 한 것과 하고 있는 것에 비해 지금 내가 하고 있는 것은 장난 수준 밖에 되지 않는 것 같다는 것 정도다.