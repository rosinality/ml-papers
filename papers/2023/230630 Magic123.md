https://arxiv.org/abs/2306.17843

Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors (Guocheng Qian, Jinjie Mai, Abdullah Hamdi, Jian Ren, Aliaksandr Siarohin, Bing Li, Hsin-Ying Lee, Ivan Skorokhodov, Peter Wonka, Sergey Tulyakov, Bernard Ghanem)

single image to 3d generation. nerf로 coarse level representation을 구성한 다음 mesh 기반 방법으로 넘겨 fine grained rendering을 만드는 방식이군요. 각각의 방법들도 충분히 복잡한데 여기에 2d, 3d prior로 각각 diffusion이 모델이 들어가는 군요.

이 계통 연구들이 지속적으로 나오는데 전 얼핏 봐서는 퀄리티의 향상을 체감하기 어렵네요. 이런 계통의 연구를 기반으로 한 도구들, 예를 들어 사진으로 게임 애셋을 만드는 도구는 상품화 되어있는 것 같던데 얼마나 쓸만할지 궁금하네요.

https://guochengqian.github.io/project/magic123/

#3d_generative_model 