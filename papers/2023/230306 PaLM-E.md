https://arxiv.org/abs/2303.03378

PaLM-E: An Embodied Multimodal Language Model (Danny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine, Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, Pete Florence)

vit + palm으로 로보틱스 과제 태클하기. image/language 결합은 요즘 유행(?)대로 이미지 임베딩을 텍스트 시퀀스의 토큰으로 끼워넣는 방식을 사용했네요. 좀 더 나아가서 이미지 임베딩으로 2d가 아닌 3d aware한 임베딩 (이미지 셋으로부터 novel view synthesis를 하도록 학습시킨 모델)을 사용해서 성능을 올릴 수 있다고 보고했군요.

흥미로운 포인트 중 하나는 모델 규모가 562B 정도까지 올라가니 로보틱스 과제에 (텍스트도 포함되어 있긴 합니다만) 파인튜닝을 해도 nlg 과제에 대한 성능이 크게 안 빠진다는 것이네요.

#robotics #llm #multimodal #3d 