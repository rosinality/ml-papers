https://arxiv.org/abs/2305.14314

QLoRA: Efficient Finetuning of Quantized LLMs (Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer)

요즘 작고 빠르게 할 수 있다고 하면 반응이 어마어마한데, 그런 측면에서 최근 가장 화제가 되는 논문일 것 같네요. 4 bit weight only quantization, quantization parameter에 대한 quantization에 lora를 결합하고 필요시 optimizer state에 소모되는 GPU 메모리를 CPU에 paging 하는 방식으로 GPU 하나에서 65B 모델을 파인튜닝하는데 성공했습니다.

이렇게 만든 모델 Guanaco가 ELO로 GPT-3.5-Turbo를 뛰어넘는 Elo를 기록했군요.

#quantization #llm #alignment #finetuning 