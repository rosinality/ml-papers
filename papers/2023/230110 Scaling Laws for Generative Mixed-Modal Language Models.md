https://arxiv.org/abs/2301.03728

Scaling Laws for Generative Mixed-Modal Language Models (Armen Aghajanyan, Lili Yu, Alexis Conneau, Wei-Ning Hsu, Karen Hambardzumyan, Susan Zhang, Stephen Roller, Naman Goyal, Omer Levy, Luke Zettlemoyer)

image/image-text/speech/speech-text/code/molecules 같은 modality에 대한 scaling law 추정과 이 modality의 pair를 같이 학습했을 떄의 bimodal scaling에 대한 결과네요. bimodal scaling에서 각 modality의 시너지와 경쟁을 고려해서 경쟁보다 시너지가 커지는 파라미터 규모를 추정한 부분이 흥미롭네요.

추가적으로 모델 크기가 일정 이하일 때 bimodal 특정 modal의 학습이 정지되는 현상과 modality에 따른 최적 배치 크기를 발견했네요.

#multimodal 