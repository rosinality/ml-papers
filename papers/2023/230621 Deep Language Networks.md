https://arxiv.org/abs/2306.12509

Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference (Alessandro Sordoni, Xingdi Yuan, Marc-Alexandre Côté, Matheus Pereira, Adam Trischler, Ziang Xiao, Arian Hosseini, Friederike Niedtner, Nicolas Le Roux)

기본적으로는 llm에 대한 prompt optimization 방법인데...여기서는 더 나아가 llm 모델의 출력을 다시 llm에 입력으로 주는 방식으로 추론한다고 했을 때 두 llm에 대한 prompt 두 개를 최적화하는 방법을 다루고 있네요. llm을 iterative하게 적용했을 때 어떤 것이 가능할지에 대한 탐색들이 요즘 보이는 듯 한데 어떻게 될지 궁금하네요.

#llm 