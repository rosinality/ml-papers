https://arxiv.org/abs/2302.03668

Hard Prompts Made Easy: Gradient-Based Discrete Optimization for Prompt Tuning and Discovery (Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum, Jonas Geiping, Tom Goldstein)

text2img의 prompt tuning 테크닉이군요. continuous vector embedding이 아니라 word token을 생성할 수 있는 것을 목표로 합니다. 방법은 비교적 심플하게 gradient descent로 임베딩을 최적화하고 가장 유사한 토큰으로 projection 하는 것의 반복이네요.

text2img의 프롬프트는 벌써 쌓인 양도 어마어마하고 영업 비밀(?)처럼 돌아다니는 것 같던데 이 부분이 꽤 재미있다고 생각합니다. 개인적으로는 AI/ML 모델이 사회에서 확산되고 채택되는 양식에 대한 하나의 흥미로운 사례라고 봅니다.

#prompt #text2img 