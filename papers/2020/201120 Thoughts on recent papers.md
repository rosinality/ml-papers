Towards Domain-Agnostic Contrastive Learning (https://arxiv.org/abs/2011.04419)
AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations from Self-Trained Negative Adversaries (https://arxiv.org/abs/2011.08435)
UP-DETR: Unsupervised Pre-training for Object Detection with Transformers (https://arxiv.org/abs/2011.09094)
Dense Contrastive Learning for Self-Supervised Visual Pre-Training (https://arxiv.org/abs/2011.09157)
Heterogeneous Contrastive Learning: Encoding Spatial Information for Compact Visual Representations (https://arxiv.org/abs/2011.09941)
Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning (https://arxiv.org/abs/2011.10043)
요즘 contrastive learning 혹은 pretraining 알고리즘들이 아주 쏟아지는 중. 아래 세 논문은 핵심 아이디어도 이미지 global한 instance/semantic한 정보의 추출(image classification)이 아니라 pixel 혹은 비교적 local한 정보, 혹은 spatial한 정보의 활용을 contrastive learning에 결합시켜 detection 혹은 segmentation 같은 downstream task에서의 성능을 향상시키는 것이 목표로 서로 비슷하다.
저자들을 체크해보지는 않았지만 비전 퍼슨들, 특히 중국쪽 디텍션 장인들이 디텍션 같은 문제에 대한 성능 향상의 방법으로 contrastive learning에 주목하고 있는(혹은 이미 주목하고 넘어간) 것이 아닌가 싶다. 아 너무 무섭다;

#review