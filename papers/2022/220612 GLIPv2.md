https://arxiv.org/abs/2206.05836

GLIPv2: Unifying Localization and Vision-Language Understanding (Haotian Zhang, Pengchuan Zhang, Xiaowei Hu, Yen-Chun Chen, Liunian Harold Li, Xiyang Dai, Lijuan Wang, Lu Yuan, Jenq-Neng Hwang, Jianfeng Gao)

제목 그대로 object localization (object detection, instance segmentation, visual grounding)과 vision-language understanding (vqa, captioning)을 위한 통합 모델 프리트레이닝. 어떻게 보면 요즘의 단순한 접근보다 훨씬 정교한 형태로 구성한 모델이라고 할 수도 있겠습니다. 이 방향도 꽤 흥미롭네요.

#vision-language 