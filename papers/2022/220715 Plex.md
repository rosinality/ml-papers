https://arxiv.org/abs/2207.07411

Plex: Towards Reliability using Pretrained Large Model Extensions (Dustin Tran, Jeremiah Liu, Michael W. Dusenberry, Du Phan, Mark Collier, Jie Ren, Kehang Han, Zi Wang, Zelda Mariet, Huiyi Hu, Neil Band, Tim G. J. Rudner, Karan Singhal, Zachary Nado, Joost van Amersfoort, Andreas Kirsch, Rodolphe Jenatton, Nithum Thain, Honglin Yuan, Kelly Buchanan, Kevin Murphy, D. Sculley, Yarin Gal, Zoubin Ghahramani, Jasper Snoek, Balaji Lakshminarayanan)

reliable한 모델 구축하기. 일단 reliability를 카테고리화.

1. Uncertainty
	1. calibration
	2. selective prediction. uncertainty가 높으면 모델이 예측을 기권하도록 했을 때의 성능
	3. open set recognition. 학습시 보지 않은 데이터를 탐지할 확률
	4. label uncertainty. 레이블이 불확실하거나 다양할 수 있을 때 모델의 성능.
2. Robust Generalization
	1. in distribution generalization. 다운스트림 데이터에 파인튜닝했을 때 모델의 성능
	2. covariate shift. 입력 분포는 바뀌었으나(사진에서 스케치로) 레이블의 조건부 분포는 바뀌지 않았을 때의 성능.
	3. subpopulation shift. 관심 분포가 학습 분포의 서브셋인 경우. 이 때 학습시 보지 않았거나 롱테일 서브셋에 대한 성능 분석.
3. Adaptation
	1. active learning.
	2. few-shot learning
	3. few-shot uncertainty. few-shot 케이스에서 calibration과 open set recognition 성능을 평가. 모델의 representation의 mahalanobis distance로 zero-shot open recognition도 테스트.

위 사례들을 평가하기 위한 데이터셋들을 구성하고 모델을 확장. (Plex: Pretrained Large model Extensions.) ViT와 T5에 대해 실험.
* 모델 크기 증가
* JFT or C4, 데이터셋 크기 증가
* 배치 앙상블
* Gaussian Process를 last layer로 사용

#uncertainty #generalization #few_shot