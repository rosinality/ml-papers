https://arxiv.org/abs/2211.05781

Demystify Transformers & Convolutions in Modern Image Deep Networks (Jifeng Dai, Min Shi, Weiyun Wang, Sitong Wu, Linjie Xing, Wenhai Wang, Xizhou Zhu, Lewei Lu, Jie Zhou, Xiaogang Wang, Yu Qiao, Xiaowei Hu)

halo attention, pooling attention, shifted window attention, depthwise conv, deformable conv v3 같은 spatial token mixer와 다양한 레이어 구성, 모델 규모에 대해 성능과 invariance에 대한 분석. 다 동일 세팅으로 맞춰놓으니 성능이 비슷비슷하긴 하고 레이어 구성에 따라 성능 차이가 꽤 크다는 것이 드러나네요.

#cnn #vit 