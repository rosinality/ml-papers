Diffusion 모델에 대한 생각.

아주 구체적이진 않긴 한데 생성 모델, 이미지 생성 모델이 주로 극복하고자 하는 문제가 서로 통한다는 생각을 해봤다. 물론 이미지를 생성하고 이미지의 확률 분포를 모델링해야 한다는 것 같은 자명한 것이 아니라 좀 다른 측면에서.

이 모델들에서 발생하는 가장 중요한 문제는 gaussian noise 같은 구조가 없는 입력에서 지극히 구조화된 데이터로, 입력과 출력을 어떻게 매핑해야 하는지가 확실하지도 않고 정해져 있지 않은 상태에서 모델을 학습시켜야 한다는 것이 아닐까? 이 문제를 어떻게 쉽게 만들 수 있는지가 요점이 되는 것이 아닌가 하는 생각이다.

예를 들어 GAN은 likelihood 모델의 카테고리에 속하진 않지만 이 페어가 없다는 문제를 discriminator를 사용한 간접적인 supervision으로 태클했고, 해소되지 않고 남아있는 노이즈를 이미지로 한 번에 매핑하는 문제의 난이도가 학습의 불안정성을 만드는 것이 아닐까.

Autoregressive 모델은 이 문제를 (특히 multimodal한 sequence 출력에 대해서) 시퀀스 전체를 출력하는 대신 단 한 스텝을 예측하는 문제로 단순화하고 ground truth 입력을 제공하는 것으로 해결한 것이 아닐까. (결과적으로 학습을 훨씬 수월하게 만들었다.)

Non autoregressive 모델은 이 출력의 불확실함과 multimodality 문제 때문에 학습이 어려운 점이 있어서 sequence knowledge distillation이 널리 사용되었고, 흔히 사용되는 접근을 보면 한 번에 임의 입력에서 출력 결과물을 생성하는 것이 아니라 단계를 나누고 마스킹(노이즈)을 사용해서 점진적으로 출력을 만들어가는 식으로 문제를 단순화해서 학습을 용이하게 만들었다고 할 수 있지 않을까.

denoising diffusion 같은 경우엔 위의 non autoregressive 모델에서 discrete한 노이즈를 점진적으로 추가하는 대신 gaussian noise 같은 것을 점진적으로 추가하는 것으로 이 까다로운 매핑 문제를 단계별로 쪼갠 형태로 푸는 것이라고 할 수 있지 않을까.

(Non autoregressive normalizing flow 같은 경우는 여전히 이미지를 노이즈 분포로 한 번에 매핑하려 시도하기 때문에, 즉 다른 모델들이 여러 단개로 나눠 수행하는 작업을 한 번에 수행하려 시도하기 때문에 막대한 깊이가 필요한 것일 수도 있지 않을까 하는 생각을 한다. 물론 invertible layer의 표현력의 한계도 존재하겠지만.)

그런 의미에선 이런 서로 다른 모델들이 생각보다 서로 통할 수도 있고 비슷할 수도 있겠다는 생각을 한다. 즉 학습시키기 어려운 매핑을 단계별로 쪼개서 학습에 용이하게 만드는 것.

수학적으로 근사하게 보일 수 있으면 좋겠지만 그 정도는 안 되고. 막연한 생각에 가깝다. (이런 막연한 생각을 이렇게 길게 써서 죄송스럽다.)