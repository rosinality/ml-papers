https://arxiv.org/abs/2106.02034

DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification (Yongming Rao, Wenliang Zhao, Benlin Liu, Jiwen Lu, Jie Zhou, Cho-Jui Hsieh)

효율적인 vit. downsampling 대신 토큰의 일부를 샘플링하는 방식. nlp나 혹은 cnn 쪽에서도 이런 형태의 효율화가 종종 나오곤 했었죠. 이 샘플링을 위해서 gumbel-softmax를 사용하는 등...제 느낌에는 좀 까다로운 접근을 쓴 것 같긴 하네요.

#vit #sparse_attention