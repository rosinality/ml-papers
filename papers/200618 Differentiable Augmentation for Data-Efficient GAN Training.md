https://arxiv.org/abs/2006.10738

Differentiable Augmentation for Data-Efficient GAN Training (Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, Song Han)

non leaking augmentation (https://arxiv.org/abs/2006.06676) 과 거의 비슷하게 real/fake 샘플 모두에 augmentation을 추가한다는 아이디어. random apply 대신 약한 강도의 augmentation이 비슷한 역할을 하는 것이 아닐지.