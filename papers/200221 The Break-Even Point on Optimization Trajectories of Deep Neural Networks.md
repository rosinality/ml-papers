https://arxiv.org/abs/2002.09572

The Break-Even Point on Optimization Trajectories of Deep Neural Networks (Stanislaw Jastrzebski, Maciej Szymczak, Stanislav Fort, Devansh Arpit, Jacek Tabor, Kyunghyun Cho, Krzysztof Geras)

뉴럴넷의 학습 과정에 break-even 지점이라는 loss의 곡률이 최대인 방향으로 진동하기 시작하는 지점이 존재. 이 지점에 도달하기 전의 hyperparameter, 특히 learning rate에 의해 이후의 학습 경로가 달라진다는 연구. 높은 learning rate를 사용한 경우 그래디언트의 분산이 감소하고 더 나은 preconditioning이 발생함. 이러한 요인들이 더 나은 성능의 모델이 학습되는 과정에 기여.

#loss #training #optimization